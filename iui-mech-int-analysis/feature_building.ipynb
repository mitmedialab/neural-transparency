{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_clean/data_participants.csv')\n",
    "\n",
    "df['delta_trust']           = df.post_trust  - df.pre_trust\n",
    "\n",
    "df['delta_unintended']      = df.post_predict_unintended_behaviors - df.pre_predict_unintended_behaviors\n",
    "\n",
    "df['delta_neg_unintended']  =  df.post_predict_negative_behaviors - df.pre_predict_negative_behaviors\n",
    "\n",
    "df.to_csv('model_data/delta_differences.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac7ba2",
   "metadata": {},
   "source": [
    "## 6. Correlating Trait Prediction\n",
    "\n",
    "- take trait predictions and see if people are correlating them correctly.\n",
    "- focus on first persona-vector generation\n",
    "- relativize the prediction based on how far they are from the midpoint -- 0 activation\n",
    "- map correctly those activations to the category to make them categorically similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_clean/persona_prediction.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions (0–10 scale)\n",
    "df_pred = pd.read_csv('data_clean/persona_prediction.csv')\n",
    "\n",
    "# Lambda: returns (left_pole, right_pole) | function can return either 0 or 0-1\n",
    "pole = lambda v: ((5 - v) / 5 if v < 5 else 0.0, (v - 5) / 5 if v > 5 else 0.0)\n",
    "\n",
    "# left column (pre): original ordinal rating\n",
    "# middle and right cols: activations in the polar directions as directed by the lambda function \"pole\"\n",
    "# structure of normalized polar values: {trait}_{pole}_{normValue}\n",
    "traits = [\n",
    "    ('pre_empathy',       'empathy_empathetic_norm',        'empathy_unempathetic_norm'),\n",
    "    ('pre_encouraging',   'encouraging_encouraging_norm',   'encouraging_discouraging_norm'),\n",
    "    ('pre_formality',     'formality_casual_norm',          'formality_formal_norm'),\n",
    "    ('pre_funniness',     'funniness_funny_norm',           'funniness_serious_norm'),\n",
    "    ('pre_hallucination', 'hallucination_factual_norm',     'hallucination_hallucinatory_norm'),\n",
    "    ('pre_honesty',       'honesty_honest_norm',            'honesty_sycophantic_norm'),\n",
    "    ('pre_sociality',     'sociality_social_norm',          'sociality_antisocial_norm'),\n",
    "    ('pre_toxicity',      'toxicity_respectful_norm',       'toxicity_toxic_norm'),\n",
    "]\n",
    "\n",
    "# Apply mapping per trait\n",
    "for src, right_col, left_col in traits:\n",
    "    left_right = df_pred[src].apply(pole).apply(pd.Series)  # col 0: left, col 1: right\n",
    "    df_pred[left_col] = left_right[0]\n",
    "    df_pred[right_col] = left_right[1]\n",
    "\n",
    "# Quick preview\n",
    "df_pred[['pre_empathy','empathy_empathetic_norm','empathy_unempathetic_norm',\n",
    "        'pre_encouraging',   'encouraging_encouraging_norm',   'encouraging_discouraging_norm',\n",
    "        'pre_formality',     'formality_casual_norm',          'formality_formal_norm',\n",
    "        'pre_funniness',     'funniness_funny_norm',           'funniness_serious_norm',\n",
    "        'pre_hallucination', 'hallucination_factual_norm',     'hallucination_hallucinatory_norm',\n",
    "        'pre_honesty',       'honesty_honest_norm',            'honesty_sycophantic_norm',\n",
    "        'pre_sociality',     'sociality_social_norm',          'sociality_antisocial_norm',\n",
    "        'pre_toxicity',         'toxicity_respectful_norm', 'toxicity_toxic_norm']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[['firebase_id', 'prolific_id', 'timestamp', 'condition', 'system_prompt',\n",
    "        'empathy_empathetic', 'empathy_unempathetic', 'encouraging_encouraging',\n",
    "        'encouraging_discouraging', 'formality_formal', 'formality_casual',\n",
    "        'funniness_funny', 'funniness_serious', 'hallucination_factual',\n",
    "        'hallucination_hallucinatory', 'sociality_social',\n",
    "        'sociality_antisocial', 'sycophancy_honest', 'sycophancy_sycophantic',\n",
    "        'toxicity_respectful', 'toxicity_toxic', 'condition_name',\n",
    "        'pre_empathy','empathy_empathetic_norm','empathy_unempathetic_norm',\n",
    "        'pre_formality','formality_formal_norm','formality_casual_norm',\n",
    "        'pre_toxicity','toxicity_respectful_norm','toxicity_toxic_norm']].to_csv('model_data/persona_prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f69a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Prepare data for empathy scatter plot, norm == participant prediction, otherwise, it's a trait activation\n",
    "empathetic_data = pd.DataFrame({\n",
    "    'Normalized Prediction': df['empathy_empathetic_norm_polar'],\n",
    "    'Activation': df['empathy_empathetic_polar'],\n",
    "    'Pole': 'Empathetic'\n",
    "})\n",
    "\n",
    "unempathetic_data = pd.DataFrame({\n",
    "    'Normalized Prediction': df['empathy_unempathetic_norm_polar'],\n",
    "    'Activation': df['empathy_unempathetic_polar'],\n",
    "    'Pole': 'Unempathetic'\n",
    "})\n",
    "\n",
    "# Combine the data\n",
    "empathy_plot_data = pd.concat([empathetic_data, unempathetic_data], ignore_index=True)\n",
    "\n",
    "empathy_plot_data.head()\n",
    "\n",
    "empathy_plot_data.to_csv('model_data/empathy_activations.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ef979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "df = pd.read_csv('model_data/empathy_activations.csv')\n",
    "\n",
    "# Combine all data for regression and plotting\n",
    "all_x = df['Normalized Prediction']\n",
    "all_y = df['Activation']\n",
    "\n",
    "# Plot all data points in grey\n",
    "ax.scatter(all_x, all_y, color='grey', alpha=0.6, s=60)\n",
    "\n",
    "# Calculate regression line\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(all_x, all_y)\n",
    "\n",
    "# Create regression line\n",
    "line_x = np.linspace(all_x.min(), all_x.max(), 100)\n",
    "line_y = slope * line_x + intercept\n",
    "\n",
    "# Calculate confidence interval for the regression line\n",
    "n = len(all_x)\n",
    "x_mean = np.mean(all_x)\n",
    "sxx = np.sum((all_x - x_mean) ** 2)\n",
    "residuals = all_y - (slope * all_x + intercept)\n",
    "mse = np.sum(residuals ** 2) / (n - 2)  # Mean squared error\n",
    "t_val = stats.t.ppf(0.975, n - 2)  # 95% confidence interval\n",
    "\n",
    "# Calculate standard error for each point on the line\n",
    "se_line = np.sqrt(mse * (1/n + (line_x - x_mean)**2 / sxx))\n",
    "ci_lower = line_y - t_val * se_line\n",
    "ci_upper = line_y + t_val * se_line\n",
    "\n",
    "# Plot regression line with confidence interval\n",
    "ax.plot(line_x, line_y, color='red', linewidth=2, linestyle='--', alpha=0.8)\n",
    "ax.fill_between(line_x, ci_lower, ci_upper, color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "# Add vertical line at x=0\n",
    "ax.axvline(x=0, color='lightgrey', linewidth=1, alpha=0.7)\n",
    "\n",
    "# Add horizontal line at y=0\n",
    "ax.axhline(y=0, color='lightgrey', linewidth=1, alpha=0.7)\n",
    "\n",
    "# Create custom legend\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color='red', linewidth=2, linestyle='--',\n",
    "               label=f'Regression (r={r_value:.3f}, R²={r_value**2:.2f}, p < 0.001)'),\n",
    "    plt.Rectangle((0,0),1,1, facecolor='black', alpha=0.2, label='95% Confidence Interval')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=16, frameon=True)\n",
    "\n",
    "# Styling to match the reference image\n",
    "ax.set_xlabel('User Prediction', fontsize=20)\n",
    "ax.set_ylabel('Persona Activation', fontsize=20)\n",
    "\n",
    "# Set axis limits and ticks to match the reference\n",
    "ax.set_xlim(-1.0, 1.1)\n",
    "ax.set_ylim(-0.6, 1.1)\n",
    "ax.set_xticks([-0.75, -0.50, -0.25, 0.00, 0.25, 0.50, 0.75, 1.00])\n",
    "ax.set_yticks([-0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# Grid styling\n",
    "ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Keep all spines visible but make them subtle\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_color('black')\n",
    "    spine.set_linewidth(0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check data distribution\n",
    "print(f\"Data distribution:\")\n",
    "print(f\"X-data mean: {x_mean:.3f}\")\n",
    "print(f\"X-data range: [{all_x.min():.3f}, {all_x.max():.3f}]\")\n",
    "print(f\"Negative values: {(all_x < 0).sum()} out of {len(all_x)} ({100*(all_x < 0).sum()/len(all_x):.1f}%)\")\n",
    "print(f\"Positive values: {(all_x > 0).sum()} out of {len(all_x)} ({100*(all_x > 0).sum()/len(all_x):.1f}%)\")\n",
    "\n",
    "# Print additional statistics\n",
    "print(f\"Correlation coefficient: {r_value:.3f}\")\n",
    "print(f\"R-squared: {r_value**2:.3f}\")\n",
    "print(f\"P-value: {p_value:.3e}\")\n",
    "print(f\"Regression equation: y = {slope:.3f}x + {intercept:.3f}\")\n",
    "print(f\"Standard error of regression: {np.sqrt(mse):.3f}\")\n",
    "\n",
    "# Print confidence interval range (min and max of the CI band)\n",
    "print(f\"\\nConfidence Interval Band Range:\")\n",
    "print(f\"CI Lower bound range: {ci_lower.min():.3f} to {ci_lower.max():.3f}\")\n",
    "print(f\"CI Upper bound range: {ci_upper.min():.3f} to {ci_upper.max():.3f}\")\n",
    "\n",
    "# Calculate 95% confidence intervals for coefficients (like JASP)\n",
    "print(f\"\\n95% Confidence Intervals for Coefficients:\")\n",
    "print(f\"Intercept: {intercept:.3f} ± {t_val * std_err * np.sqrt(1/n + x_mean**2/sxx):.3f}\")\n",
    "print(f\"Slope: {slope:.3f} ± {t_val * std_err * np.sqrt(1/sxx):.3f}\")\n",
    "\n",
    "# More precise coefficient CIs\n",
    "se_intercept = np.sqrt(mse * (1/n + x_mean**2/sxx))\n",
    "se_slope = np.sqrt(mse/sxx)\n",
    "intercept_ci_lower = intercept - t_val * se_intercept\n",
    "intercept_ci_upper = intercept + t_val * se_intercept\n",
    "slope_ci_lower = slope - t_val * se_slope\n",
    "slope_ci_upper = slope + t_val * se_slope\n",
    "\n",
    "print(f\"\\nCoefficient 95% CIs (matching JASP format):\")\n",
    "print(f\"Intercept: [{intercept_ci_lower:.3f}, {intercept_ci_upper:.3f}]\")\n",
    "print(f\"Slope: [{slope_ci_lower:.3f}, {slope_ci_upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b96223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "df = pd.read_csv('model_data/empathy_activations.csv')\n",
    "\n",
    "# Combine all data for regression and plotting\n",
    "all_x = df['Normalized Prediction']\n",
    "all_y = df['Activation']\n",
    "\n",
    "# Plot all data points in grey\n",
    "ax.scatter(all_x, all_y, color='grey', alpha=0.6, s=60)\n",
    "\n",
    "# Calculate regression line\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(all_x, all_y)\n",
    "\n",
    "# Create regression line\n",
    "line_x = np.linspace(all_x.min(), all_x.max(), 100)\n",
    "line_y = slope * line_x + intercept\n",
    "\n",
    "# Calculate confidence interval for the regression line\n",
    "n = len(all_x)\n",
    "x_mean = np.mean(all_x)\n",
    "sxx = np.sum((all_x - x_mean) ** 2)\n",
    "residuals = all_y - (slope * all_x + intercept)\n",
    "mse = np.sum(residuals ** 2) / (n - 2)  # Mean squared error\n",
    "t_val = stats.t.ppf(0.975, n - 2)  # 95% confidence interval\n",
    "\n",
    "# Calculate standard error for each point on the line\n",
    "se_line = np.sqrt(mse * (1/n + (line_x - x_mean)**2 / sxx))\n",
    "ci_lower = line_y - t_val * se_line\n",
    "ci_upper = line_y + t_val * se_line\n",
    "\n",
    "# Plot regression line with confidence interval\n",
    "ax.plot(line_x, line_y, color='red', linewidth=2, linestyle='--', alpha=0.8)\n",
    "ax.fill_between(line_x, ci_lower, ci_upper, color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "# Add vertical line at x=0\n",
    "ax.axvline(x=0, color='lightgrey', linewidth=1, alpha=0.7)\n",
    "\n",
    "# Add horizontal line at y=0\n",
    "ax.axhline(y=0, color='lightgrey', linewidth=1, alpha=0.7)\n",
    "\n",
    "# Create custom legend\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color='red', linewidth=2, linestyle='--',\n",
    "               label=f'Regression (r={r_value:.3f}, R²={r_value**2:.2f}, p < 0.001)'),\n",
    "    plt.Rectangle((0,0),1,1, facecolor='black', alpha=0.2, label='95% Confidence Interval')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=16, frameon=True)\n",
    "\n",
    "# Styling to match the reference image\n",
    "ax.set_xlabel('User Prediction', fontsize=20)\n",
    "ax.set_ylabel('Persona Activation', fontsize=20)\n",
    "\n",
    "# Set axis limits and ticks to match the reference\n",
    "ax.set_xlim(-1.0, 1.1)\n",
    "ax.set_ylim(-0.6, 1.1)\n",
    "ax.set_xticks([-0.75, -0.50, -0.25, 0.00, 0.25, 0.50, 0.75, 1.00])\n",
    "ax.set_yticks([-0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# Grid styling\n",
    "ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Remove top and right spines, keep only bottom and left (x and y axes)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['bottom'].set_linewidth(0.8)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check data distribution\n",
    "print(f\"Data distribution:\")\n",
    "print(f\"X-data mean: {x_mean:.3f}\")\n",
    "print(f\"X-data range: [{all_x.min():.3f}, {all_x.max():.3f}]\")\n",
    "print(f\"Negative values: {(all_x < 0).sum()} out of {len(all_x)} ({100*(all_x < 0).sum()/len(all_x):.1f}%)\")\n",
    "print(f\"Positive values: {(all_x > 0).sum()} out of {len(all_x)} ({100*(all_x > 0).sum()/len(all_x):.1f}%)\")\n",
    "\n",
    "# Print additional statistics\n",
    "print(f\"Correlation coefficient: {r_value:.3f}\")\n",
    "print(f\"R-squared: {r_value**2:.3f}\")\n",
    "print(f\"P-value: {p_value:.3e}\")\n",
    "print(f\"Regression equation: y = {slope:.3f}x + {intercept:.3f}\")\n",
    "print(f\"Standard error of regression: {np.sqrt(mse):.3f}\")\n",
    "\n",
    "# Print confidence interval range (min and max of the CI band)\n",
    "print(f\"\\nConfidence Interval Band Range:\")\n",
    "print(f\"CI Lower bound range: {ci_lower.min():.3f} to {ci_lower.max():.3f}\")\n",
    "print(f\"CI Upper bound range: {ci_upper.min():.3f} to {ci_upper.max():.3f}\")\n",
    "\n",
    "# Calculate 95% confidence intervals for coefficients (like JASP)\n",
    "print(f\"\\n95% Confidence Intervals for Coefficients:\")\n",
    "print(f\"Intercept: {intercept:.3f} ± {t_val * std_err * np.sqrt(1/n + x_mean**2/sxx):.3f}\")\n",
    "print(f\"Slope: {slope:.3f} ± {t_val * std_err * np.sqrt(1/sxx):.3f}\")\n",
    "\n",
    "# More precise coefficient CIs\n",
    "se_intercept = np.sqrt(mse * (1/n + x_mean**2/sxx))\n",
    "se_slope = np.sqrt(mse/sxx)\n",
    "intercept_ci_lower = intercept - t_val * se_intercept\n",
    "intercept_ci_upper = intercept + t_val * se_intercept\n",
    "slope_ci_lower = slope - t_val * se_slope\n",
    "slope_ci_upper = slope + t_val * se_slope\n",
    "\n",
    "print(f\"\\nCoefficient 95% CIs (matching JASP format):\")\n",
    "print(f\"Intercept: [{intercept_ci_lower:.3f}, {intercept_ci_upper:.3f}]\")\n",
    "print(f\"Slope: [{slope_ci_lower:.3f}, {slope_ci_upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate correlations for each pole\n",
    "empathetic_corr, empathetic_p = stats.pearsonr(\n",
    "    df['empathy_empathetic_norm_polar'], \n",
    "    df['empathy_empathetic_polar']\n",
    ")\n",
    "\n",
    "unempathetic_corr, unempathetic_p = stats.pearsonr(\n",
    "    df['empathy_unempathetic_norm_polar'], \n",
    "    df['empathy_unempathetic_polar']\n",
    ")\n",
    "\n",
    "print(\"Empathy Prediction Accuracy Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nEmpathetic:\")\n",
    "print(f\"  Pearson r = {empathetic_corr:.3f}\")\n",
    "print(f\"  p-value = {empathetic_p:.4f}\")\n",
    "print(f\"  Significant: {'Yes' if empathetic_p < 0.05 else 'No'}\")\n",
    "\n",
    "print(f\"\\nUnempathetic:\")\n",
    "print(f\"  Pearson r = {unempathetic_corr:.3f}\")\n",
    "print(f\"  p-value = {unempathetic_p:.4f}\")\n",
    "print(f\"  Significant: {'Yes' if unempathetic_p < 0.05 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d57a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Create bipolar representations\n",
    "# Positive = empathetic, Negative = unempathetic\n",
    "empathy_prediction_bipolar = pd.concat([\n",
    "    df['empathy_empathetic_norm_polar'],      # Keep positive\n",
    "    -df['empathy_unempathetic_norm_polar']    # Flip to negative\n",
    "])\n",
    "\n",
    "empathy_activation_bipolar = pd.concat([\n",
    "    df['empathy_empathetic_polar'],           # Keep positive\n",
    "    -df['empathy_unempathetic_polar']         # Flip to negative\n",
    "])\n",
    "\n",
    "# Create combined dataframe\n",
    "empathy_bipolar_data = pd.DataFrame({\n",
    "    'Prediction': empathy_prediction_bipolar,\n",
    "    'Activation': empathy_activation_bipolar\n",
    "})\n",
    "\n",
    "empathy_bipolar_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate correlation for the entire bipolar trait\n",
    "corr, p_value = stats.pearsonr(\n",
    "    empathy_bipolar_data['Prediction'], \n",
    "    empathy_bipolar_data['Activation']\n",
    ")\n",
    "\n",
    "print(\"Empathy Bipolar Trait - Prediction Accuracy\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Pearson r = {corr:.3f}\")\n",
    "print(f\"p-value = {p_value:.4f}\")\n",
    "print(f\"R² = {corr**2:.3f} (variance explained)\")\n",
    "print(f\"Significant: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data (with all norm columns now)\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define trait mappings: (positive_pole, negative_pole)\n",
    "trait_mappings = {\n",
    "    'empathy': ('empathetic', 'unempathetic'),\n",
    "    'encouraging': ('encouraging', 'discouraging'),\n",
    "    'formality': ('casual', 'formal'),  # Casual is positive, Formal is negative\n",
    "    'funniness': ('funny', 'serious'),\n",
    "    'hallucination': ('factual', 'hallucinatory'),\n",
    "    'honesty': ('honest', 'sycophantic'),  # Changed from 'sycophancy' to 'honesty'\n",
    "    'sociality': ('social', 'antisocial'),\n",
    "    'toxicity': ('respectful', 'toxic'),\n",
    "}\n",
    "\n",
    "# Metadata columns to keep\n",
    "metadata_cols = ['firebase_id', 'prolific_id', 'timestamp', 'condition', 'system_prompt', 'condition_name',\n",
    "                 'pre_empathy', 'pre_encouraging', 'pre_formality', 'pre_funniness', \n",
    "                 'pre_hallucination', 'pre_honesty', 'pre_sociality', 'pre_toxicity']\n",
    "\n",
    "# Create new dataframe with metadata\n",
    "result_df = df[metadata_cols].copy()\n",
    "\n",
    "# Process each trait\n",
    "for trait, (pos_pole, neg_pole) in trait_mappings.items():\n",
    "    # Activation columns\n",
    "    pos_col = f'{trait}_{pos_pole}'\n",
    "    neg_col = f'{trait}_{neg_pole}'\n",
    "    \n",
    "    if pos_col in df.columns:\n",
    "        # Positive pole: keep as-is, add _polar suffix\n",
    "        result_df[f'{pos_col}_polar'] = df[pos_col]\n",
    "    \n",
    "    if neg_col in df.columns:\n",
    "        # Negative pole: multiply by -1, add _polar suffix\n",
    "        result_df[f'{neg_col}_polar'] = df[neg_col] * -1\n",
    "    \n",
    "    # Norm columns (if they exist)\n",
    "    pos_norm_col = f'{trait}_{pos_pole}_norm'\n",
    "    neg_norm_col = f'{trait}_{neg_pole}_norm'\n",
    "    \n",
    "    if pos_norm_col in df.columns:\n",
    "        # Positive pole norm: keep as-is, add _polar suffix\n",
    "        result_df[f'{pos_norm_col}_polar'] = df[pos_norm_col]\n",
    "    \n",
    "    if neg_norm_col in df.columns:\n",
    "        # Negative pole norm: multiply by -1, add _polar suffix\n",
    "        result_df[f'{neg_norm_col}_polar'] = df[neg_norm_col] * -1\n",
    "\n",
    "# Save the result\n",
    "result_df.to_csv('model_data/persona_prediction.csv', index=False)\n",
    "\n",
    "print(f\"✓ Transformation complete!\")\n",
    "print(f\"✓ Original columns: {len(df.columns)}\")\n",
    "print(f\"✓ New columns: {len(result_df.columns)}\")\n",
    "print(f\"\\nNew column structure:\")\n",
    "print(f\"  - Metadata columns: {len(metadata_cols)}\")\n",
    "print(f\"  - Polar columns: {len(result_df.columns) - len(metadata_cols)}\")\n",
    "\n",
    "# Display the first few rows\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1797ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Load the polar data\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Combine empathy polar data (both poles into single bipolar representation)\n",
    "empathy_prediction_polar = pd.concat([\n",
    "    df['empathy_empathetic_norm_polar'],      # Positive values\n",
    "    df['empathy_unempathetic_norm_polar']     # Negative values (already flipped)\n",
    "])\n",
    "\n",
    "empathy_activation_polar = pd.concat([\n",
    "    df['empathy_empathetic_polar'],           # Positive values\n",
    "    df['empathy_unempathetic_polar']          # Negative values (already flipped)\n",
    "])\n",
    "\n",
    "# Create dataframe for plotting\n",
    "empathy_data = pd.DataFrame({\n",
    "    'Prediction': empathy_prediction_polar,\n",
    "    'Activation': empathy_activation_polar\n",
    "})\n",
    "\n",
    "empathy_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine encouraging polar data (both poles into single bipolar representation)\n",
    "encouraging_prediction_polar = pd.concat([\n",
    "    df['encouraging_encouraging_norm_polar'],      # Positive values\n",
    "    df['encouraging_discouraging_norm_polar']      # Negative values (already flipped)\n",
    "])\n",
    "\n",
    "encouraging_activation_polar = pd.concat([\n",
    "    df['encouraging_encouraging_polar'],           # Positive values\n",
    "    df['encouraging_discouraging_polar']           # Negative values (already flipped)\n",
    "])\n",
    "\n",
    "# Create dataframe for plotting\n",
    "encouraging_data = pd.DataFrame({\n",
    "    'Prediction': encouraging_prediction_polar,\n",
    "    'Activation': encouraging_activation_polar\n",
    "})\n",
    "\n",
    "encouraging_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns exist in the dataframe\n",
    "print(\"Available columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf8f0e",
   "metadata": {},
   "source": [
    "### Trying again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original predictions (0–10 scale)\n",
    "df_pred = pd.read_csv('data_clean/persona_prediction.csv')\n",
    "\n",
    "# Lambda: returns (left_pole, right_pole)\n",
    "pole = lambda v: ((5 - v) / 5 if v < 5 else 0.0, (v - 5) / 5 if v > 5 else 0.0)\n",
    "\n",
    "# source_col, right_col_name, left_col_name\n",
    "traits = [\n",
    "    ('pre_empathy',       'empathy_empathetic_norm',        'empathy_unempathetic_norm'),\n",
    "    ('pre_encouraging',   'encouraging_encouraging_norm',   'encouraging_discouraging_norm'),\n",
    "    ('pre_formality',     'formality_casual_norm',          'formality_formal_norm'),\n",
    "    ('pre_funniness',     'funniness_funny_norm',           'funniness_serious_norm'),\n",
    "    ('pre_hallucination', 'hallucination_factual_norm',     'hallucination_hallucinatory_norm'),\n",
    "    ('pre_honesty',       'honesty_honest_norm',            'honesty_sycophantic_norm'),\n",
    "    ('pre_sociality',     'sociality_social_norm',          'sociality_antisocial_norm'),\n",
    "    ('pre_toxicity',      'toxicity_respectful_norm',       'toxicity_toxic_norm'),\n",
    "]\n",
    "\n",
    "# Apply mapping per trait\n",
    "for src, right_col, left_col in traits:\n",
    "    left_right = df_pred[src].apply(pole).apply(pd.Series)  # col 0: left, col 1: right\n",
    "    df_pred[left_col] = left_right[0]\n",
    "    df_pred[right_col] = left_right[1]\n",
    "\n",
    "# Save with norm columns\n",
    "df_pred.to_csv('model_data/persona_prediction.csv', index=False)\n",
    "\n",
    "print(\"✓ Step 1 complete: Normalization for all traits!\")\n",
    "print(f\"Total columns: {len(df_pred.columns)}\")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the normalized data\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define trait mappings: (trait_name_for_activation, trait_name_for_norm, positive_pole, negative_pole)\n",
    "trait_mappings = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'unempathetic'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'discouraging'),\n",
    "    ('formality', 'formality', 'casual', 'formal'),\n",
    "    ('funniness', 'funniness', 'funny', 'serious'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'hallucinatory'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'sycophantic'),  # Different names!\n",
    "    ('sociality', 'sociality', 'social', 'antisocial'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'toxic'),\n",
    "]\n",
    "\n",
    "# Metadata columns to keep\n",
    "metadata_cols = ['firebase_id', 'prolific_id', 'timestamp', 'condition', 'system_prompt', 'condition_name',\n",
    "                 'pre_empathy', 'pre_encouraging', 'pre_formality', 'pre_funniness', \n",
    "                 'pre_hallucination', 'pre_honesty', 'pre_sociality', 'pre_toxicity']\n",
    "\n",
    "# Create new dataframe with metadata\n",
    "result_df = df[metadata_cols].copy()\n",
    "\n",
    "# Process each trait\n",
    "for trait_act, trait_norm, pos_pole, neg_pole in trait_mappings:\n",
    "    # Activation columns (use trait_act)\n",
    "    pos_col = f'{trait_act}_{pos_pole}'\n",
    "    neg_col = f'{trait_act}_{neg_pole}'\n",
    "    \n",
    "    if pos_col in df.columns:\n",
    "        result_df[f'{pos_col}_polar'] = df[pos_col]\n",
    "    \n",
    "    if neg_col in df.columns:\n",
    "        result_df[f'{neg_col}_polar'] = df[neg_col] * -1\n",
    "    \n",
    "    # Norm columns (use trait_norm)\n",
    "    pos_norm_col = f'{trait_norm}_{pos_pole}_norm'\n",
    "    neg_norm_col = f'{trait_norm}_{neg_pole}_norm'\n",
    "    \n",
    "    if pos_norm_col in df.columns:\n",
    "        result_df[f'{pos_norm_col}_polar'] = df[pos_norm_col]\n",
    "    \n",
    "    if neg_norm_col in df.columns:\n",
    "        result_df[f'{neg_norm_col}_polar'] = df[neg_norm_col] * -1\n",
    "\n",
    "# Save the result\n",
    "result_df.to_csv('model_data/persona_prediction.csv', index=False)\n",
    "\n",
    "print(f\"✓ Step 2 complete: Polar transformation (CORRECTED)!\")\n",
    "print(f\"Total columns: {len(result_df.columns)}\")\n",
    "\n",
    "# Check columns\n",
    "activation_polar_cols = [col for col in result_df.columns if '_polar' in col and '_norm_polar' not in col]\n",
    "norm_polar_cols = [col for col in result_df.columns if '_norm_polar' in col]\n",
    "print(f\"\\nActivation polar columns: {len(activation_polar_cols)}\")\n",
    "print(f\"Norm polar columns: {len(norm_polar_cols)}\")\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f48a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Load the polar data\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Combine encouraging polar data (both poles into single bipolar representation)\n",
    "encouraging_prediction_polar = pd.concat([\n",
    "    df['encouraging_encouraging_norm_polar'],      # Positive values\n",
    "    df['encouraging_discouraging_norm_polar']      # Negative values (already flipped)\n",
    "])\n",
    "\n",
    "encouraging_activation_polar = pd.concat([\n",
    "    df['encouraging_encouraging_polar'],           # Positive values\n",
    "    df['encouraging_discouraging_polar']           # Negative values (already flipped)\n",
    "])\n",
    "\n",
    "# Create dataframe for plotting\n",
    "encouraging_data = pd.DataFrame({\n",
    "    'Prediction': encouraging_prediction_polar,\n",
    "    'Activation': encouraging_activation_polar\n",
    "})\n",
    "\n",
    "encouraging_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ede316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Check a few examples\n",
    "print(\"Checking empathy transformations:\\n\")\n",
    "for idx in [0, 1, 2, 10, 20]:\n",
    "    if idx >= len(df):\n",
    "        continue\n",
    "    \n",
    "    pre = df.loc[idx, 'pre_empathy']\n",
    "    emp_norm = df.loc[idx, 'empathy_empathetic_norm_polar']\n",
    "    unemp_norm = df.loc[idx, 'empathy_unempathetic_norm_polar']\n",
    "    \n",
    "    print(f\"Participant {idx}:\")\n",
    "    print(f\"  pre_empathy = {pre}\")\n",
    "    print(f\"  Expected: empathetic_norm = {max(0, (pre-5)/5):.2f}, unempathetic_norm = {max(0, (5-pre)/5)*-1:.2f}\")\n",
    "    print(f\"  Actual:   empathetic_norm = {emp_norm:.2f}, unempathetic_norm = {unemp_norm:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "firebase_id = df.loc[18, 'firebase_id']\n",
    "prolific_id = df.loc[18, 'prolific_id']\n",
    "condition = df.loc[18, 'condition_name']\n",
    "\n",
    "print(f\"Participant 18:\")\n",
    "print(f\"  Firebase ID: {firebase_id}\")\n",
    "print(f\"  Prolific ID: {prolific_id}\")\n",
    "print(f\"  Condition: {condition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a47ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Get participant 18's data\n",
    "p18 = df.loc[18]\n",
    "\n",
    "traits = [\n",
    "    ('Empathy', 'empathy', 'empathy', 'empathetic', 'unempathetic', 'Empathetic', 'Unempathetic'),\n",
    "    ('Encouraging', 'encouraging', 'encouraging', 'encouraging', 'discouraging', 'Encouraging', 'Discouraging'),\n",
    "    ('Formality', 'formality', 'formality', 'casual', 'formal', 'Casual', 'Formal'),\n",
    "    ('Funniness', 'funniness', 'funniness', 'funny', 'serious', 'Funny', 'Serious'),\n",
    "    ('Hallucination', 'hallucination', 'hallucination', 'factual', 'hallucinatory', 'Factual', 'Hallucinatory'),\n",
    "    ('Honesty', 'sycophancy', 'honesty', 'honest', 'sycophantic', 'Honest', 'Sycophantic'),\n",
    "    ('Sociality', 'sociality', 'sociality', 'social', 'antisocial', 'Social', 'Antisocial'),\n",
    "    ('Toxicity', 'toxicity', 'toxicity', 'respectful', 'toxic', 'Respectful', 'Toxic'),\n",
    "]\n",
    "\n",
    "print(\"\\\\begin{table}[h]\")\n",
    "print(\"\\\\centering\")\n",
    "print(\"\\\\caption{Example Participant Trait Predictions vs Actual Activations}\")\n",
    "print(\"\\\\label{tab:participant18}\")\n",
    "print(\"\\\\begin{tabular}{lcccccc}\")\n",
    "print(\"\\\\hline\")\n",
    "print(\"\\\\textbf{Trait} & \\\\multicolumn{2}{c}{\\\\textbf{Predicted}} & \\\\multicolumn{2}{c}{\\\\textbf{Actual}} & \\\\multicolumn{2}{c}{\\\\textbf{Error}} \\\\\\\\\")\n",
    "print(\"               & Positive & Negative & Positive & Negative & Positive & Negative \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "\n",
    "total_error = 0\n",
    "error_count = 0\n",
    "\n",
    "for trait_name, trait_act, trait_norm, pos_pole, neg_pole, pos_label, neg_label in traits:\n",
    "    pred_pos = p18[f'{trait_norm}_{pos_pole}_norm_polar']\n",
    "    pred_neg = p18[f'{trait_norm}_{neg_pole}_norm_polar']\n",
    "    act_pos = p18[f'{trait_act}_{pos_pole}_polar']\n",
    "    act_neg = p18[f'{trait_act}_{neg_pole}_polar']\n",
    "    \n",
    "    error_pos = abs(pred_pos - act_pos)\n",
    "    error_neg = abs(pred_neg - act_neg)\n",
    "    \n",
    "    total_error += error_pos + error_neg\n",
    "    error_count += 2\n",
    "    \n",
    "    print(f\"{trait_name:15s} & {pred_pos:5.2f} & {pred_neg:5.2f} & {act_pos:5.2f} & {act_neg:5.2f} & {error_pos:5.2f} & {error_neg:5.2f} \\\\\\\\\")\n",
    "\n",
    "mae = total_error / error_count\n",
    "print(\"\\\\hline\")\n",
    "print(f\"\\\\multicolumn{{7}}{{l}}{{\\\\textbf{{Mean Absolute Error:}} {mae:.3f}}} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "\n",
    "# Add system prompt as a table note\n",
    "system_prompt = p18['system_prompt'].replace('&', '\\\\&').replace('_', '\\\\_').replace('%', '\\\\%')\n",
    "# Break long prompt into multiple lines if needed\n",
    "print(\"\\\\multicolumn{7}{p{0.9\\\\textwidth}}{\\\\small \\\\textbf{System Prompt:} \" + system_prompt + \"} \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "print(\"\\\\end{tabular}\")\n",
    "print(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits with poles\n",
    "trait_poles = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'Empathetic'),\n",
    "    ('empathy', 'empathy', 'unempathetic', 'Unempathetic'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'Encouraging'),\n",
    "    ('encouraging', 'encouraging', 'discouraging', 'Discouraging'),\n",
    "    ('formality', 'formality', 'casual', 'Casual'),\n",
    "    ('formality', 'formality', 'formal', 'Formal'),\n",
    "    ('funniness', 'funniness', 'funny', 'Funny'),\n",
    "    ('funniness', 'funniness', 'serious', 'Serious'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'Factual'),\n",
    "    ('hallucination', 'hallucination', 'hallucinatory', 'Hallucinatory'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'Honest'),\n",
    "    ('sycophancy', 'honesty', 'sycophantic', 'Sycophantic'),\n",
    "    ('sociality', 'sociality', 'social', 'Social'),\n",
    "    ('sociality', 'sociality', 'antisocial', 'Antisocial'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'Respectful'),\n",
    "    ('toxicity', 'toxicity', 'toxic', 'Toxic'),\n",
    "]\n",
    "\n",
    "# Calculate mean prediction and mean activation for each trait pole\n",
    "mean_predictions = []\n",
    "mean_activations = []\n",
    "labels = []\n",
    "\n",
    "for trait_act, trait_norm, pole, label in trait_poles:\n",
    "    # Get absolute values (remove negative sign for plotting)\n",
    "    pred_col = f'{trait_norm}_{pole}_norm_polar'\n",
    "    act_col = f'{trait_act}_{pole}_polar'\n",
    "    \n",
    "    mean_pred = df[pred_col].abs().mean()\n",
    "    mean_act = df[act_col].abs().mean()\n",
    "    \n",
    "    mean_predictions.append(mean_pred)\n",
    "    mean_activations.append(mean_act)\n",
    "    labels.append(label)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Scatter plot\n",
    "scatter = ax.scatter(mean_predictions, mean_activations, s=150, alpha=0.7, \n",
    "                     c=range(len(labels)), cmap='tab20')\n",
    "\n",
    "# Add diagonal line (perfect prediction)\n",
    "max_val = max(max(mean_predictions), max(mean_activations))\n",
    "ax.plot([0, max_val], [0, max_val], 'k--', linewidth=2, alpha=0.5, label='Perfect Prediction')\n",
    "\n",
    "# Add labels to points\n",
    "for i, label in enumerate(labels):\n",
    "    ax.annotate(label, (mean_predictions[i], mean_activations[i]), \n",
    "                fontsize=9, alpha=0.8, \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Labels and styling\n",
    "ax.set_xlabel('Mean Predicted Activation (|normalized|)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Mean Actual Activation (|absolute value|)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Systematic Over/Under-Estimation of Trait Activations', fontsize=15, fontweight='bold', pad=20)\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Add text annotations for interpretation\n",
    "ax.text(0.05, 0.95, 'Above line = Underestimated\\n(actual > predicted)', \n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "ax.text(0.95, 0.05, 'Below line = Overestimated\\n(predicted > actual)', \n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='bottom',\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "\n",
    "# Clean styling\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate overall bias\n",
    "overall_diff = np.array(mean_activations) - np.array(mean_predictions)\n",
    "print(f\"\\nSystematic Bias Analysis:\")\n",
    "print(f\"  Mean difference (actual - predicted): {overall_diff.mean():.4f}\")\n",
    "print(f\"  Positive = Underestimation, Negative = Overestimation\")\n",
    "print(f\"\\nTraits most underestimated (actual >> predicted):\")\n",
    "sorted_diffs = sorted(zip(labels, overall_diff), key=lambda x: x[1], reverse=True)\n",
    "for label, diff in sorted_diffs[:5]:\n",
    "    print(f\"    {label:15s}: {diff:+.4f}\")\n",
    "print(f\"\\nTraits most overestimated (predicted >> actual):\")\n",
    "for label, diff in sorted_diffs[-5:]:\n",
    "    print(f\"    {label:15s}: {diff:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits\n",
    "traits = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'unempathetic', 'Empathy'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'discouraging', 'Encouraging'),\n",
    "    ('formality', 'formality', 'casual', 'formal', 'Formality'),\n",
    "    ('funniness', 'funniness', 'funny', 'serious', 'Funniness'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'hallucinatory', 'Hallucination'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'sycophantic', 'Honesty'),\n",
    "    ('sociality', 'sociality', 'social', 'antisocial', 'Sociality'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'toxic', 'Toxicity'),\n",
    "]\n",
    "\n",
    "# Create figure with subplots (4 rows x 2 columns)\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (trait_act, trait_norm, pos_pole, neg_pole, title) in enumerate(traits):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Combine polar data (bipolar representation)\n",
    "    prediction_polar = pd.concat([\n",
    "        df[f'{trait_norm}_{pos_pole}_norm_polar'],\n",
    "        df[f'{trait_norm}_{neg_pole}_norm_polar']\n",
    "    ])\n",
    "    \n",
    "    activation_polar = pd.concat([\n",
    "        df[f'{trait_act}_{pos_pole}_polar'],\n",
    "        df[f'{trait_act}_{neg_pole}_polar']\n",
    "    ])\n",
    "    \n",
    "    # Create violin plots\n",
    "    parts = ax.violinplot([prediction_polar, activation_polar], \n",
    "                          positions=[1, 2], \n",
    "                          showmeans=True, showmedians=True,\n",
    "                          widths=0.7)\n",
    "    \n",
    "    # Color the violins\n",
    "    for pc, color in zip(parts['bodies'], ['lightblue', 'lightcoral']):\n",
    "        pc.set_facecolor(color)\n",
    "        pc.set_alpha(0.7)\n",
    "    \n",
    "    # Customize mean and median lines\n",
    "    parts['cmeans'].set_color('black')\n",
    "    parts['cmeans'].set_linewidth(2)\n",
    "    parts['cmedians'].set_color('darkred')\n",
    "    parts['cmedians'].set_linewidth(2)\n",
    "    \n",
    "    # Add box plots on top for quartiles\n",
    "    bp = ax.boxplot([prediction_polar, activation_polar], \n",
    "                    positions=[1, 2], \n",
    "                    widths=0.3,\n",
    "                    patch_artist=True,\n",
    "                    showfliers=False,\n",
    "                    boxprops=dict(facecolor='white', alpha=0.5),\n",
    "                    whiskerprops=dict(linewidth=1.5),\n",
    "                    capprops=dict(linewidth=1.5))\n",
    "    \n",
    "    # Add reference line at zero\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Labels and styling\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels(['Predicted', 'Actual'], fontsize=11)\n",
    "    ax.set_ylabel('Activation (Bipolar)', fontsize=10)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_pred = prediction_polar.mean()\n",
    "    mean_act = activation_polar.mean()\n",
    "    std_pred = prediction_polar.std()\n",
    "    std_act = activation_polar.std()\n",
    "    \n",
    "    textstr = f'μ_pred={mean_pred:.3f} (σ={std_pred:.3f})\\nμ_act={mean_act:.3f} (σ={std_act:.3f})'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=8,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.suptitle('Distribution of Predicted vs Actual Trait Activations', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.995])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6857b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits\n",
    "traits = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'unempathetic', 'Empathy'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'discouraging', 'Encouraging'),\n",
    "    ('formality', 'formality', 'casual', 'formal', 'Formality'),\n",
    "    ('funniness', 'funniness', 'funny', 'serious', 'Funniness'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'hallucinatory', 'Hallucination'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'sycophantic', 'Honesty'),\n",
    "    ('sociality', 'sociality', 'social', 'antisocial', 'Sociality'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'toxic', 'Toxicity'),\n",
    "]\n",
    "\n",
    "# Create figure with subplots (4 rows x 2 columns)\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (trait_act, trait_norm, pos_pole, neg_pole, title) in enumerate(traits):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Combine polar data (bipolar representation)\n",
    "    prediction_polar = pd.concat([\n",
    "        df[f'{trait_norm}_{pos_pole}_norm_polar'],\n",
    "        df[f'{trait_norm}_{neg_pole}_norm_polar']\n",
    "    ])\n",
    "    \n",
    "    activation_polar = pd.concat([\n",
    "        df[f'{trait_act}_{pos_pole}_polar'],\n",
    "        df[f'{trait_act}_{neg_pole}_polar']\n",
    "    ])\n",
    "    \n",
    "    # Create box plots\n",
    "    bp = ax.boxplot([prediction_polar, activation_polar], \n",
    "                    positions=[1, 2], \n",
    "                    widths=0.5,\n",
    "                    patch_artist=True,\n",
    "                    showmeans=True,\n",
    "                    meanprops=dict(marker='D', markerfacecolor='red', markeredgecolor='red', markersize=8),\n",
    "                    boxprops=dict(facecolor='lightblue', alpha=0.7, linewidth=1.5),\n",
    "                    medianprops=dict(color='darkblue', linewidth=2),\n",
    "                    whiskerprops=dict(linewidth=1.5),\n",
    "                    capprops=dict(linewidth=1.5),\n",
    "                    flierprops=dict(marker='o', markerfacecolor='gray', markersize=5, alpha=0.5))\n",
    "    \n",
    "    # Color the boxes differently\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    bp['boxes'][1].set_facecolor('lightcoral')\n",
    "    \n",
    "    # Add reference line at zero\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Set y-axis limits to -1 to 1\n",
    "    ax.set_ylim(-1, 1)\n",
    "    \n",
    "    # Labels and styling\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels(['Predicted', 'Actual'], fontsize=11)\n",
    "    ax.set_ylabel('Activation (Bipolar)', fontsize=10)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_pred = prediction_polar.mean()\n",
    "    mean_act = activation_polar.mean()\n",
    "    \n",
    "    textstr = f'μ_pred={mean_pred:.3f}\\nμ_act={mean_act:.3f}'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    \n",
    "    # Clean styling\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distribution of Predicted vs Actual Trait Activations', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.995])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits\n",
    "traits = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'unempathetic', 'Empathy'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'discouraging', 'Encouraging'),\n",
    "    ('formality', 'formality', 'casual', 'formal', 'Formality'),\n",
    "    ('funniness', 'funniness', 'funny', 'serious', 'Funniness'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'hallucinatory', 'Hallucination'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'sycophantic', 'Honesty'),\n",
    "    ('sociality', 'sociality', 'social', 'antisocial', 'Sociality'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'toxic', 'Toxicity'),\n",
    "]\n",
    "\n",
    "print(\"STATISTICAL TESTS: Predicted vs Actual Activations\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNote: Tests are on paired differences (actual - predicted)\")\n",
    "print(\"Positive mean difference = Underestimation, Negative = Overestimation\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for trait_act, trait_norm, pos_pole, neg_pole, title in traits:\n",
    "    print(f\"\\n{title.upper()}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Combine polar data (bipolar representation)\n",
    "    prediction_polar = pd.concat([\n",
    "        df[f'{trait_norm}_{pos_pole}_norm_polar'],\n",
    "        df[f'{trait_norm}_{neg_pole}_norm_polar']\n",
    "    ])\n",
    "    \n",
    "    activation_polar = pd.concat([\n",
    "        df[f'{trait_act}_{pos_pole}_polar'],\n",
    "        df[f'{trait_act}_{neg_pole}_polar']\n",
    "    ])\n",
    "    \n",
    "    # Calculate differences (actual - predicted)\n",
    "    differences = activation_polar - prediction_polar\n",
    "    \n",
    "    # Descriptive statistics\n",
    "    mean_diff = differences.mean()\n",
    "    std_diff = differences.std()\n",
    "    mean_pred = prediction_polar.mean()\n",
    "    mean_act = activation_polar.mean()\n",
    "    \n",
    "    # Test for normality of differences (Shapiro-Wilk)\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(differences)\n",
    "    is_normal = shapiro_p > 0.05\n",
    "    \n",
    "    # Paired t-test\n",
    "    t_stat, t_pval = stats.ttest_rel(activation_polar, prediction_polar)\n",
    "    \n",
    "    # Wilcoxon signed-rank test (non-parametric)\n",
    "    wilcoxon_stat, wilcoxon_pval = stats.wilcoxon(activation_polar, prediction_polar)\n",
    "    \n",
    "    # Effect size (Cohen's d for paired samples)\n",
    "    cohens_d = mean_diff / std_diff\n",
    "    \n",
    "    print(f\"  Mean Predicted: {mean_pred:.4f}\")\n",
    "    print(f\"  Mean Actual:    {mean_act:.4f}\")\n",
    "    print(f\"  Mean Difference: {mean_diff:.4f} (SD = {std_diff:.4f})\")\n",
    "    print(f\"\\n  Normality Test (Shapiro-Wilk):\")\n",
    "    print(f\"    W = {shapiro_stat:.4f}, p = {shapiro_p:.4f} {'✓ Normal' if is_normal else '✗ Non-normal'}\")\n",
    "    print(f\"\\n  Paired t-test:\")\n",
    "    print(f\"    t = {t_stat:.4f}, p = {t_pval:.4f} {'***' if t_pval < 0.001 else '**' if t_pval < 0.01 else '*' if t_pval < 0.05 else 'n.s.'}\")\n",
    "    print(f\"\\n  Wilcoxon signed-rank test (non-parametric):\")\n",
    "    print(f\"    W = {wilcoxon_stat:.4f}, p = {wilcoxon_pval:.4f} {'***' if wilcoxon_pval < 0.001 else '**' if wilcoxon_pval < 0.01 else '*' if wilcoxon_pval < 0.05 else 'n.s.'}\")\n",
    "    print(f\"\\n  Effect Size (Cohen's d): {cohens_d:.4f} ({'small' if abs(cohens_d) < 0.5 else 'medium' if abs(cohens_d) < 0.8 else 'large'})\")\n",
    "    \n",
    "    results.append({\n",
    "        'Trait': title,\n",
    "        'Mean_Predicted': mean_pred,\n",
    "        'Mean_Actual': mean_act,\n",
    "        'Mean_Diff': mean_diff,\n",
    "        'Cohens_d': cohens_d,\n",
    "        't_stat': t_stat,\n",
    "        't_pval': t_pval,\n",
    "        'wilcoxon_pval': wilcoxon_pval,\n",
    "        'normal': is_normal\n",
    "    })\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\" * 80)\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Bonferroni correction for multiple comparisons\n",
    "alpha = 0.05\n",
    "n_tests = len(traits)\n",
    "bonferroni_alpha = alpha / n_tests\n",
    "print(f\"\\n\\nBonferroni-corrected significance level: α = {bonferroni_alpha:.4f}\")\n",
    "print(f\"Significant after correction (t-test):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    if row['t_pval'] < bonferroni_alpha:\n",
    "        print(f\"  {row['Trait']}: p = {row['t_pval']:.4f} ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cafdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits with poles\n",
    "trait_poles = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'Empathetic'),\n",
    "    ('empathy', 'empathy', 'unempathetic', 'Unempathetic'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'Encouraging'),\n",
    "    ('encouraging', 'encouraging', 'discouraging', 'Discouraging'),\n",
    "    ('formality', 'formality', 'casual', 'Casual'),\n",
    "    ('formality', 'formality', 'formal', 'Formal'),\n",
    "    ('funniness', 'funniness', 'funny', 'Funny'),\n",
    "    ('funniness', 'funniness', 'serious', 'Serious'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'Factual'),\n",
    "    ('hallucination', 'hallucination', 'hallucinatory', 'Hallucinatory'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'Honest'),\n",
    "    ('sycophancy', 'honesty', 'sycophantic', 'Sycophantic'),\n",
    "    ('sociality', 'sociality', 'social', 'Social'),\n",
    "    ('sociality', 'sociality', 'antisocial', 'Antisocial'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'Respectful'),\n",
    "    ('toxicity', 'toxicity', 'toxic', 'Toxic'),\n",
    "]\n",
    "\n",
    "# Collect all predicted and actual values (absolute values)\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "for trait_act, trait_norm, pole, label in trait_poles:\n",
    "    pred_col = f'{trait_norm}_{pole}_norm_polar'\n",
    "    act_col = f'{trait_act}_{pole}_polar'\n",
    "    \n",
    "    predicted.extend(df[pred_col].abs().tolist())\n",
    "    actual.extend(df[act_col].abs().tolist())\n",
    "\n",
    "# Create dataframe for JASP\n",
    "jasp_data = pd.DataFrame({\n",
    "    'predicted': predicted,\n",
    "    'actual': actual,\n",
    "    'difference': np.array(predicted) - np.array(actual)\n",
    "})\n",
    "\n",
    "# Save\n",
    "jasp_data.to_csv('model_data/predicted_vs_actual_jasp.csv', index=False)\n",
    "\n",
    "print(f\"Total observations: {len(jasp_data)}\")\n",
    "print(f\"\\nDescriptive statistics:\")\n",
    "print(jasp_data.describe())\n",
    "print(f\"\\nMean predicted: {jasp_data['predicted'].mean():.4f}\")\n",
    "print(f\"Mean actual:    {jasp_data['actual'].mean():.4f}\")\n",
    "print(f\"Mean difference: {jasp_data['difference'].mean():.4f}\")\n",
    "print(f\"\\nSaved to: model_data/predicted_vs_actual_jasp.csv\")\n",
    "\n",
    "jasp_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f906afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits with poles\n",
    "trait_poles = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'Empathetic'),\n",
    "    ('empathy', 'empathy', 'unempathetic', 'Unempathetic'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'Encouraging'),\n",
    "    ('encouraging', 'encouraging', 'discouraging', 'Discouraging'),\n",
    "    ('formality', 'formality', 'casual', 'Casual'),\n",
    "    ('formality', 'formality', 'formal', 'Formal'),\n",
    "    ('funniness', 'funniness', 'funny', 'Funny'),\n",
    "    ('funniness', 'funniness', 'serious', 'Serious'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'Factual'),\n",
    "    ('hallucination', 'hallucination', 'hallucinatory', 'Hallucinatory'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'Honest'),\n",
    "    ('sycophancy', 'honesty', 'sycophantic', 'Sycophantic'),\n",
    "    ('sociality', 'sociality', 'social', 'Social'),\n",
    "    ('sociality', 'sociality', 'antisocial', 'Antisocial'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'Respectful'),\n",
    "    ('toxicity', 'toxicity', 'toxic', 'Toxic'),\n",
    "]\n",
    "\n",
    "# Create long-format data: one row per participant per trait pole\n",
    "rows = []\n",
    "\n",
    "for trait_act, trait_norm, pole, label in trait_poles:\n",
    "    pred_col = f'{trait_norm}_{pole}_norm_polar'\n",
    "    act_col = f'{trait_act}_{pole}_polar'\n",
    "    \n",
    "    for idx in range(len(df)):\n",
    "        rows.append({\n",
    "            'trait_pole': label,\n",
    "            'predicted': abs(df.loc[idx, pred_col]),\n",
    "            'actual': abs(df.loc[idx, act_col]),\n",
    "            'difference': abs(df.loc[idx, pred_col]) - abs(df.loc[idx, act_col])\n",
    "        })\n",
    "\n",
    "jasp_data = pd.DataFrame(rows)\n",
    "\n",
    "# Save\n",
    "jasp_data.to_csv('model_data/predicted_vs_actual_by_trait.csv', index=False)\n",
    "\n",
    "print(f\"Total observations: {len(jasp_data)} ({len(df)} participants × 16 trait poles)\")\n",
    "print(f\"\\nOverall:\")\n",
    "print(f\"  Mean predicted: {jasp_data['predicted'].mean():.4f}\")\n",
    "print(f\"  Mean actual:    {jasp_data['actual'].mean():.4f}\")\n",
    "print(f\"  Mean difference: {jasp_data['difference'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nBy trait pole:\")\n",
    "summary = jasp_data.groupby('trait_pole')[['predicted', 'actual', 'difference']].mean()\n",
    "summary = summary.sort_values('difference')\n",
    "print(summary)\n",
    "\n",
    "print(f\"\\nSaved to: model_data/predicted_vs_actual_by_trait.csv\")\n",
    "\n",
    "jasp_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6390c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits with poles\n",
    "trait_poles = [\n",
    "    ('empathy', 'empathy', 'empathetic'),\n",
    "    ('empathy', 'empathy', 'unempathetic'),\n",
    "    ('encouraging', 'encouraging', 'encouraging'),\n",
    "    ('encouraging', 'encouraging', 'discouraging'),\n",
    "    ('formality', 'formality', 'casual'),\n",
    "    ('formality', 'formality', 'formal'),\n",
    "    ('funniness', 'funniness', 'funny'),\n",
    "    ('funniness', 'funniness', 'serious'),\n",
    "    ('hallucination', 'hallucination', 'factual'),\n",
    "    ('hallucination', 'hallucination', 'hallucinatory'),\n",
    "    ('sycophancy', 'honesty', 'honest'),\n",
    "    ('sycophancy', 'honesty', 'sycophantic'),\n",
    "    ('sociality', 'sociality', 'social'),\n",
    "    ('sociality', 'sociality', 'antisocial'),\n",
    "    ('toxicity', 'toxicity', 'respectful'),\n",
    "    ('toxicity', 'toxicity', 'toxic'),\n",
    "]\n",
    "\n",
    "# Create wide-format data\n",
    "jasp_data = pd.DataFrame()\n",
    "\n",
    "for trait_act, trait_norm, pole in trait_poles:\n",
    "    pred_col = f'{trait_norm}_{pole}_norm_polar'\n",
    "    act_col = f'{trait_act}_{pole}_polar'\n",
    "    \n",
    "    # Add columns with absolute values\n",
    "    jasp_data[f'predicted_{pole}'] = df[pred_col].abs()\n",
    "    jasp_data[f'actual_{pole}'] = df[act_col].abs()\n",
    "\n",
    "# Save\n",
    "jasp_data.to_csv('model_data/predicted_vs_actual_wide.csv', index=False)\n",
    "\n",
    "print(f\"Shape: {jasp_data.shape} ({jasp_data.shape[0]} participants × {jasp_data.shape[1]} columns)\")\n",
    "print(f\"\\nColumns: {list(jasp_data.columns)}\")\n",
    "print(f\"\\nSaved to: model_data/predicted_vs_actual_wide.csv\")\n",
    "\n",
    "jasp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857f322",
   "metadata": {},
   "source": [
    "## Systematic Over/Underestimation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set nice font\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "# plt.rcParams['font.serif'] = ['Georgia', 'Times New Roman']\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Results from JASP (standard Cohen's d with 95% CIs)\n",
    "results = {\n",
    "    'trait': ['Empathetic', 'Unempathetic', 'Encouraging', 'Discouraging',\n",
    "              'Casual', 'Formal', 'Funny', 'Serious',\n",
    "              'Factual', 'Hallucinatory', 'Honest', 'Sycophantic',\n",
    "              'Social', 'Antisocial', 'Respectful'],\n",
    "    't': [6.642, 0.095, 10.648, -1.512, 9.509, -3.147, 9.290, -16.286,\n",
    "          8.796, 1.569, 9.477, -3.789, 0.240, 2.093, -2.615],\n",
    "    'p': [0.0001, 0.924, 0.0001, 0.135, 0.0001, 0.002, 0.0001, 0.0001,\n",
    "          0.0001, 0.121, 0.0001, 0.0001, 0.811, 0.040, 0.011],\n",
    "    'cohens_d': [0.743, 0.011, 1.191, -0.169, 1.063, -0.352, 1.039, -1.821,\n",
    "                 0.983, 0.175, 1.060, -0.424, 0.027, 0.234, -0.292],\n",
    "    'ci_lower': [0.493, -0.208, 0.901, -0.389, 0.786, -0.577, 0.764, -2.177,\n",
    "                 0.714, -0.046, 0.783, -0.651, -0.192, 0.011, -0.515],\n",
    "    'ci_upper': [0.988, 0.230, 1.475, 0.052, 1.336, -0.125, 1.309, -1.460,\n",
    "                 1.249, 0.396, 1.332, -0.194, 0.246, 0.455, -0.068]\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results = df_results.sort_values('cohens_d')\n",
    "\n",
    "# Use the actual JASP confidence intervals (AFTER sorting)\n",
    "# Calculate asymmetric error bars for plotting\n",
    "df_results['ci_error_lower'] = df_results['cohens_d'] - df_results['ci_lower']\n",
    "df_results['ci_error_upper'] = df_results['ci_upper'] - df_results['cohens_d']\n",
    "\n",
    "# For matplotlib, we need the error values as arrays [lower_errors, upper_errors]\n",
    "ci_errors = [df_results['ci_error_lower'].values, df_results['ci_error_upper'].values]\n",
    "\n",
    "# Create figure - single plot, more compact\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Gray color scheme\n",
    "color = '#808080'\n",
    "\n",
    "# Create bars with JASP 95% CI error bars (asymmetric)\n",
    "bars = ax.barh(df_results['trait'], df_results['cohens_d'],\n",
    "               color=color, alpha=0.85, edgecolor='#2d2d2d', linewidth=0.8,\n",
    "               xerr=ci_errors, capsize=3,\n",
    "               error_kw={'linewidth': 1.5, 'ecolor': '#2d2d2d'})\n",
    "\n",
    "# Add significance markers\n",
    "for i, (idx, row) in enumerate(df_results.iterrows()):\n",
    "    if row['p'] < 0.001:\n",
    "        marker = '***'\n",
    "    elif row['p'] < 0.01:\n",
    "        marker = '**'\n",
    "    elif row['p'] < 0.05:\n",
    "        marker = '*'\n",
    "    else:\n",
    "        marker = ''\n",
    "    \n",
    "    if marker:\n",
    "        # Use the actual CI bounds for positioning significance markers\n",
    "        x_pos = row['ci_upper'] + 0.08\n",
    "        if row['cohens_d'] < 0:\n",
    "            x_pos = row['ci_lower'] - 0.08\n",
    "        ax.text(x_pos, i, marker, va='center',\n",
    "                ha='left' if row['cohens_d'] > 0 else 'right',\n",
    "                fontsize=9, color='#2d2d2d', fontweight='bold')\n",
    "\n",
    "# Reference lines\n",
    "ax.axvline(x=0, color='#2d2d2d', linewidth=1.2, linestyle='-', zorder=0)\n",
    "\n",
    "# Subtle styling\n",
    "ax.set_xlabel(\"Cohen's d (with 95% CI)\", fontsize=16, color='#2d2d2d', fontweight='600')\n",
    "ax.set_ylabel(\"\")\n",
    "# ax.set_title(\"Systematic Over/Under-Estimation of Trait Activations\",\n",
    "#              fontsize=12, fontweight='600', color='#2d2d2d', pad=12)\n",
    "\n",
    "# Clean up spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(0.8)\n",
    "ax.spines['left'].set_color('#2d2d2d')\n",
    "ax.spines['bottom'].set_linewidth(0.8)\n",
    "ax.spines['bottom'].set_color('#2d2d2d')\n",
    "\n",
    "# Grid\n",
    "ax.grid(axis='x', alpha=0.15, linestyle='-', linewidth=0.5, color='#2d2d2d')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Tighter layout\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/overprediction_barplot_95ci.png', dpi=300, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved to: figures/overprediction_barplot_95ci.png\")\n",
    "\n",
    "# Print JASP confidence intervals for verification\n",
    "print(\"\\nJASP 95% Confidence Intervals:\")\n",
    "print(\"Trait\\t\\t\\tCohen's d\\tCI Lower\\tCI Upper\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in df_results.iterrows():\n",
    "    print(f\"{row['trait']:<15}\\t{row['cohens_d']:.3f}\\t\\t{row['ci_lower']:.3f}\\t\\t{row['ci_upper']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ddc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress, pearsonr\n",
    "\n",
    "# Load the polar data\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define all traits\n",
    "traits = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'unempathetic', 'Empathy'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'discouraging', 'Encouraging'),\n",
    "    ('formality', 'formality', 'casual', 'formal', 'Formality'),\n",
    "    ('funniness', 'funniness', 'funny', 'serious', 'Funniness'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'hallucinatory', 'Hallucination'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'sycophantic', 'Honesty'),\n",
    "    ('sociality', 'sociality', 'social', 'antisocial', 'Sociality'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'toxic', 'Toxicity'),\n",
    "]\n",
    "\n",
    "# Calculate correlations for each trait\n",
    "correlation_results = []\n",
    "\n",
    "for trait_act, trait_norm, pos_pole, neg_pole, title in traits:\n",
    "    # Combine polar data (bipolar representation)\n",
    "    prediction_polar = pd.concat([\n",
    "        df[f'{trait_norm}_{pos_pole}_norm_polar'],\n",
    "        df[f'{trait_norm}_{neg_pole}_norm_polar']\n",
    "    ])\n",
    "    \n",
    "    activation_polar = pd.concat([\n",
    "        df[f'{trait_act}_{pos_pole}_polar'],\n",
    "        df[f'{trait_act}_{neg_pole}_polar']\n",
    "    ])\n",
    "    \n",
    "    # Calculate correlation\n",
    "    r, p = pearsonr(prediction_polar, activation_polar)\n",
    "    \n",
    "    # Calculate regression\n",
    "    slope, intercept, r_reg, p_reg, stderr = linregress(prediction_polar, activation_polar)\n",
    "    \n",
    "    # Calculate directional accuracy (% correct predictions)\n",
    "    sign_mismatch = (prediction_polar * activation_polar) < 0\n",
    "    directional_accuracy = (1 - sign_mismatch.sum() / len(sign_mismatch)) * 100\n",
    "    \n",
    "    correlation_results.append({\n",
    "        'Trait': title,\n",
    "        'r': r,\n",
    "        'r²': r**2,\n",
    "        'p': p,\n",
    "        'Significance': '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'n.s.',\n",
    "        'Directional_Accuracy_%': directional_accuracy,\n",
    "        'n': len(prediction_polar)\n",
    "    })\n",
    "\n",
    "# Create dataframe\n",
    "corr_df = pd.DataFrame(correlation_results)\n",
    "\n",
    "# Sort by correlation strength\n",
    "corr_df = corr_df.sort_values('r', ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "corr_df.to_csv('model_data/prediction_correlations_summary.csv', index=False)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"PREDICTION ACCURACY: CORRELATIONS BETWEEN PREDICTED AND ACTUAL ACTIVATIONS\")\n",
    "print(\"=\" * 90)\n",
    "print()\n",
    "print(corr_df.to_string(index=False))\n",
    "print()\n",
    "print(\"=\" * 90)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"Mean correlation (r):        {corr_df['r'].mean():.3f}\")\n",
    "print(f\"Median correlation (r):      {corr_df['r'].median():.3f}\")\n",
    "print(f\"Range:                       {corr_df['r'].min():.3f} to {corr_df['r'].max():.3f}\")\n",
    "print(f\"Mean R²:                     {corr_df['r²'].mean():.3f} ({corr_df['r²'].mean()*100:.1f}% variance explained)\")\n",
    "print(f\"Traits with r > 0.5:         {(corr_df['r'] > 0.5).sum()}/8\")\n",
    "print(f\"Significant correlations:    {(corr_df['p'] < 0.05).sum()}/8\")\n",
    "print(f\"Mean directional accuracy:   {corr_df['Directional_Accuracy_%'].mean():.1f}%\")\n",
    "print()\n",
    "\n",
    "# Textual summary for reporting\n",
    "print(\"=\" * 90)\n",
    "print(\"TEXTUAL SUMMARY FOR REPORTING\")\n",
    "print(\"=\" * 90)\n",
    "print()\n",
    "print(\"Prediction-activation correlations ranged from r = {:.3f} (p {}) for {} to\".format(\n",
    "    corr_df.iloc[-1]['r'], \n",
    "    '<.001' if corr_df.iloc[-1]['p'] < 0.001 else f\"= {corr_df.iloc[-1]['p']:.3f}\",\n",
    "    corr_df.iloc[-1]['Trait']\n",
    "))\n",
    "print(\"r = {:.3f} (p {}) for {}. Overall, the mean correlation was r = {:.3f},\".format(\n",
    "    corr_df.iloc[0]['r'],\n",
    "    '<.001' if corr_df.iloc[0]['p'] < 0.001 else f\"= {corr_df.iloc[0]['p']:.3f}\",\n",
    "    corr_df.iloc[0]['Trait'],\n",
    "    corr_df['r'].mean()\n",
    "))\n",
    "print(\"explaining an average of {:.1f}% of the variance in actual trait activations.\".format(\n",
    "    corr_df['r²'].mean() * 100\n",
    "))\n",
    "print()\n",
    "\n",
    "# Strong vs weak predictors\n",
    "strong = corr_df[corr_df['r'] > 0.5]\n",
    "weak = corr_df[corr_df['r'] < 0.3]\n",
    "\n",
    "if len(strong) > 0:\n",
    "    print(\"Participants showed strong prediction accuracy for {} ({}).\".format(\n",
    "        ', '.join(strong['Trait'].tolist()[:-1]) + (' and ' + strong['Trait'].tolist()[-1] if len(strong) > 1 else strong['Trait'].tolist()[0]),\n",
    "        ', '.join([f\"r = {r:.3f}\" for r in strong['r'].tolist()])\n",
    "    ))\n",
    "    print()\n",
    "\n",
    "if len(weak) > 0:\n",
    "    print(\"Weaker correlations were observed for {} ({}).\".format(\n",
    "        ', '.join(weak['Trait'].tolist()[:-1]) + (' and ' + weak['Trait'].tolist()[-1] if len(weak) > 1 else weak['Trait'].tolist()[0]),\n",
    "        ', '.join([f\"r = {r:.3f}\" for r in weak['r'].tolist()])\n",
    "    ))\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 90)\n",
    "\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('model_data/persona_prediction.csv')\n",
    "\n",
    "# Define traits\n",
    "traits = [\n",
    "    ('empathy', 'empathy', 'empathetic', 'unempathetic', 'Empathy'),\n",
    "    ('encouraging', 'encouraging', 'encouraging', 'discouraging', 'Encouraging'),\n",
    "    ('formality', 'formality', 'casual', 'formal', 'Formality'),\n",
    "    ('funniness', 'funniness', 'funny', 'serious', 'Funniness'),\n",
    "    ('hallucination', 'hallucination', 'factual', 'hallucinatory', 'Hallucination'),\n",
    "    ('sycophancy', 'honesty', 'honest', 'sycophantic', 'Honesty'),\n",
    "    ('sociality', 'sociality', 'social', 'antisocial', 'Sociality'),\n",
    "    ('toxicity', 'toxicity', 'respectful', 'toxic', 'Toxicity'),\n",
    "]\n",
    "\n",
    "# Calculate correlations\n",
    "results = []\n",
    "\n",
    "for trait_act, trait_norm, pos_pole, neg_pole, title in traits:\n",
    "    # Combine both poles\n",
    "    predicted = pd.concat([\n",
    "        df[f'{trait_norm}_{pos_pole}_norm_polar'],\n",
    "        df[f'{trait_norm}_{neg_pole}_norm_polar']\n",
    "    ])\n",
    "    \n",
    "    actual = pd.concat([\n",
    "        df[f'{trait_act}_{pos_pole}_polar'],\n",
    "        df[f'{trait_act}_{neg_pole}_polar']\n",
    "    ])\n",
    "    \n",
    "    # Correlation\n",
    "    r, p = pearsonr(predicted, actual)\n",
    "    \n",
    "    results.append({\n",
    "        'Trait': title,\n",
    "        'r': f\"{r:.3f}\",\n",
    "        'p': f\"{p:.3f}\" if p >= 0.001 else \"<.001\",\n",
    "        'sig': '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''\n",
    "    })\n",
    "\n",
    "# Create table\n",
    "corr_table = pd.DataFrame(results)\n",
    "\n",
    "print(\"Correlations: Predicted vs Actual Activations\")\n",
    "print(\"=\" * 50)\n",
    "print(corr_table.to_string(index=False))\n",
    "\n",
    "corr_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc68170",
   "metadata": {},
   "source": [
    "## Suvey Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set font to DejaVu Sans (similar to Inter and widely available)\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data_clean/data_participants.csv')\n",
    "\n",
    "# Define the rating questions\n",
    "post_questions = {\n",
    "    'post_visualization_helpful': 'Visualization helped understand AI behavior',\n",
    "    'post_see_visualization_again': 'Would like to see visualization again',\n",
    "}\n",
    "\n",
    "between_groups = {\n",
    "    'post_trust': 'Trust in the AI after interaction',\n",
    "    'post_arrived_desired_character': 'Arrived at desired character',\n",
    "}\n",
    "\n",
    "def calculate_distribution(df_subset, column):\n",
    "    \"\"\"Calculate percentage distribution for ratings 1-7\"\"\"\n",
    "    total = df_subset[column].notna().sum()\n",
    "    if total == 0:\n",
    "        return [0] * 7\n",
    "    \n",
    "    distribution = []\n",
    "    for rating in range(1, 8):\n",
    "        count = (df_subset[column] == rating).sum()\n",
    "        percentage = (count / total) * 100\n",
    "        distribution.append(percentage)\n",
    "    return distribution\n",
    "\n",
    "# Split by condition\n",
    "experimental_df = df[df['condition_name'] == 'experimental']\n",
    "control_df = df[df['condition_name'] == 'control']\n",
    "\n",
    "# Color scheme (red to green gradient)\n",
    "colors = ['#d73027', '#fc8d59', '#fee090', '#d9d9d9', '#91cf60', '#66bd63', '#1a9850']\n",
    "\n",
    "# Create figure with adjusted spacing\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 7), gridspec_kw={'height_ratios': [1, 1], 'hspace': 0.2})\n",
    "\n",
    "# Panel 1: Between groups (split by condition) - MINIMAL LABELS\n",
    "def create_grouped_stacked_bars(ax, questions_dict):\n",
    "    questions_list = list(questions_dict.keys())\n",
    "    labels = list(questions_dict.values())\n",
    "    \n",
    "    experimental_data = [calculate_distribution(experimental_df, q) for q in questions_list]\n",
    "    control_data = [calculate_distribution(control_df, q) for q in questions_list]\n",
    "    \n",
    "    bar_height = 0.35\n",
    "    pair_spacing = 1.0\n",
    "    n_questions = len(labels)\n",
    "    y_positions = np.arange(n_questions) * pair_spacing\n",
    "    \n",
    "    # Plot control group (top of each pair)\n",
    "    left_ctrl = np.zeros(n_questions)\n",
    "    for i, color in enumerate(colors):\n",
    "        values = [d[i] for d in control_data]\n",
    "        bars = ax.barh(y_positions - bar_height/2 - 0.03, values, bar_height, left=left_ctrl, \n",
    "                       color=color, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        # Add percentage labels (only if >= 5%) - ALL WHITE\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            if value >= 5:\n",
    "                x_pos = left_ctrl[j] + value / 2\n",
    "                ax.text(x_pos, bar.get_y() + bar.get_height() / 2, \n",
    "                       f'{int(value)}', \n",
    "                       ha='center', va='center', fontsize=18, fontweight='bold',\n",
    "                       color='white')\n",
    "        \n",
    "        left_ctrl += values\n",
    "    \n",
    "    # Plot experimental group (bottom of each pair)\n",
    "    left_exp = np.zeros(n_questions)\n",
    "    for i, color in enumerate(colors):\n",
    "        values = [d[i] for d in experimental_data]\n",
    "        bars = ax.barh(y_positions + bar_height/2 + 0.03, values, bar_height, left=left_exp, \n",
    "                       color=color, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        # Add percentage labels (only if >= 5%) - ALL WHITE\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            if value >= 5:\n",
    "                x_pos = left_exp[j] + value / 2\n",
    "                ax.text(x_pos, bar.get_y() + bar.get_height() / 2, \n",
    "                       f'{int(value)}', \n",
    "                       ha='center', va='center', fontsize=18, fontweight='bold',\n",
    "                       color='white')\n",
    "        \n",
    "        left_exp += values\n",
    "    \n",
    "    # Minimal formatting - no labels\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(-0.5, y_positions[-1] + 0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Panel 2: Post questions (no condition split) - MINIMAL LABELS\n",
    "def create_single_stacked_bars(ax, questions_dict):\n",
    "    questions_list = list(questions_dict.keys())\n",
    "    labels = list(questions_dict.values())\n",
    "    \n",
    "    data = [calculate_distribution(df, q) for q in questions_list]\n",
    "    \n",
    "    bar_width = 0.65\n",
    "    y_positions = np.arange(len(labels))\n",
    "    \n",
    "    left = np.zeros(len(labels))\n",
    "    for i, color in enumerate(colors):\n",
    "        values = [d[i] for d in data]\n",
    "        bars = ax.barh(y_positions, values, bar_width, left=left, \n",
    "                       color=color, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        # Add percentage labels (only if >= 5%) - ALL WHITE\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            if value >= 5:\n",
    "                x_pos = left[j] + value / 2\n",
    "                ax.text(x_pos, bar.get_y() + bar.get_height() / 2, \n",
    "                       f'{int(value)}', \n",
    "                       ha='center', va='center', fontsize=18, fontweight='bold',\n",
    "                       color='white')\n",
    "        \n",
    "        left += values\n",
    "    \n",
    "    # Minimal formatting - no labels\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(-0.5, len(labels) - 0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Create the two panels\n",
    "create_grouped_stacked_bars(axes[0], between_groups)\n",
    "create_single_stacked_bars(axes[1], post_questions)\n",
    "\n",
    "# Remove all spacing and padding for clean export, but keep panel separation\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0.4)\n",
    "\n",
    "plt.savefig('figures/subjective_ratings_stacked_bars.png', dpi=300, bbox_inches='tight', \n",
    "           pad_inches=0, facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Chart saved to: figures/subjective_ratings_stacked_bars.png\")\n",
    "print(f\"All participants n={len(df)}\")\n",
    "print(f\"Experimental group n={len(experimental_df)}, Control group n={len(control_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Set font to Helvetica\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data_clean/data_participants.csv')\n",
    "\n",
    "# Define the rating questions\n",
    "post_questions = {\n",
    "    'post_visualization_helpful': 'Visualization helped understand AI behavior',\n",
    "    'post_see_visualization_again': 'Would like to see visualization again',\n",
    "}\n",
    "\n",
    "between_groups = {\n",
    "    'post_trust': 'Trust in the AI after interaction',\n",
    "    'post_arrived_desired_character': 'Arrived at desired character',\n",
    "}\n",
    "\n",
    "def calculate_distribution(df_subset, column):\n",
    "    \"\"\"Calculate percentage distribution for ratings 1-7\"\"\"\n",
    "    total = df_subset[column].notna().sum()\n",
    "    if total == 0:\n",
    "        return [0] * 7\n",
    "    \n",
    "    distribution = []\n",
    "    for rating in range(1, 8):\n",
    "        count = (df_subset[column] == rating).sum()\n",
    "        percentage = (count / total) * 100\n",
    "        distribution.append(percentage)\n",
    "    return distribution\n",
    "\n",
    "# Split by condition\n",
    "experimental_df = df[df['condition_name'] == 'experimental']\n",
    "control_df = df[df['condition_name'] == 'control']\n",
    "\n",
    "# Color scheme (red to green gradient)\n",
    "colors = ['#d73027', '#fc8d59', '#fee090', '#d9d9d9', '#91cf60', '#66bd63', '#1a9850']\n",
    "\n",
    "# Create figure with adjusted spacing for legend\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 8), gridspec_kw={'height_ratios': [1, 1], 'hspace': 0.2})\n",
    "\n",
    "# Panel 1: Between groups (split by condition)\n",
    "def create_grouped_stacked_bars(ax, questions_dict):\n",
    "    questions_list = list(questions_dict.keys())\n",
    "    labels = list(questions_dict.values())\n",
    "    \n",
    "    experimental_data = [calculate_distribution(experimental_df, q) for q in questions_list]\n",
    "    control_data = [calculate_distribution(control_df, q) for q in questions_list]\n",
    "    \n",
    "    bar_height = 0.35\n",
    "    pair_spacing = 1.0\n",
    "    n_questions = len(labels)\n",
    "    y_positions = np.arange(n_questions) * pair_spacing\n",
    "    \n",
    "    # Plot control group (top of each pair)\n",
    "    left_ctrl = np.zeros(n_questions)\n",
    "    for i, color in enumerate(colors):\n",
    "        values = [d[i] for d in control_data]\n",
    "        bars = ax.barh(y_positions - bar_height/2 - 0.03, values, bar_height, left=left_ctrl, \n",
    "                       color=color, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        # Add percentage labels (only if >= 5%)\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            if value >= 5:\n",
    "                x_pos = left_ctrl[j] + value / 2\n",
    "                ax.text(x_pos, bar.get_y() + bar.get_height() / 2, \n",
    "                       f'{int(value)}', \n",
    "                       ha='center', va='center', fontsize=18, fontweight='bold',\n",
    "                       color='white')\n",
    "        \n",
    "        left_ctrl += values\n",
    "    \n",
    "    # Plot experimental group (bottom of each pair)\n",
    "    left_exp = np.zeros(n_questions)\n",
    "    for i, color in enumerate(colors):\n",
    "        values = [d[i] for d in experimental_data]\n",
    "        bars = ax.barh(y_positions + bar_height/2 + 0.03, values, bar_height, left=left_exp, \n",
    "                       color=color, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        # Add percentage labels (only if >= 5%)\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            if value >= 5:\n",
    "                x_pos = left_exp[j] + value / 2\n",
    "                ax.text(x_pos, bar.get_y() + bar.get_height() / 2, \n",
    "                       f'{int(value)}', \n",
    "                       ha='center', va='center', fontsize=18, fontweight='bold',\n",
    "                       color='white')\n",
    "        \n",
    "        left_exp += values\n",
    "    \n",
    "    # Minimal formatting\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(-0.5, y_positions[-1] + 0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Panel 2: Post questions (no condition split)\n",
    "def create_single_stacked_bars(ax, questions_dict):\n",
    "    questions_list = list(questions_dict.keys())\n",
    "    labels = list(questions_dict.values())\n",
    "    \n",
    "    data = [calculate_distribution(df, q) for q in questions_list]\n",
    "    \n",
    "    bar_width = 0.65\n",
    "    y_positions = np.arange(len(labels))\n",
    "    \n",
    "    left = np.zeros(len(labels))\n",
    "    for i, color in enumerate(colors):\n",
    "        values = [d[i] for d in data]\n",
    "        bars = ax.barh(y_positions, values, bar_width, left=left, \n",
    "                       color=color, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        # Add percentage labels (only if >= 5%)\n",
    "        for j, (bar, value) in enumerate(zip(bars, values)):\n",
    "            if value >= 5:\n",
    "                x_pos = left[j] + value / 2\n",
    "                ax.text(x_pos, bar.get_y() + bar.get_height() / 2, \n",
    "                       f'{int(value)}', \n",
    "                       ha='center', va='center', fontsize=18, fontweight='bold',\n",
    "                       color='white')\n",
    "        \n",
    "        left += values\n",
    "    \n",
    "    # Minimal formatting\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(-0.5, len(labels) - 0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Create the two panels\n",
    "create_grouped_stacked_bars(axes[0], between_groups)\n",
    "create_single_stacked_bars(axes[1], post_questions)\n",
    "\n",
    "# Add legend at the bottom\n",
    "legend_labels = ['1 (Not at all)', '2', '3', '4 (Neutral)', '5', '6', '7 (Extremely)']\n",
    "legend_handles = [Rectangle((0, 0), 1, 1, fc=color) for color in colors]\n",
    "\n",
    "# Create legend below the plot\n",
    "fig.legend(legend_handles, legend_labels, loc='lower center', ncol=7, \n",
    "          frameon=False, fontsize=18, bbox_to_anchor=(0.5, -0.02))\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(left=0, bottom=0.05, right=1, top=1, wspace=0, hspace=0.4)\n",
    "\n",
    "plt.savefig('figures/subjective_ratings_stacked_bars.png', dpi=300, bbox_inches='tight', \n",
    "           pad_inches=0.1, facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Chart saved to: figures/subjective_ratings_stacked_bars.png\")\n",
    "print(f\"All participants n={len(df)}\")\n",
    "print(f\"Experimental group n={len(experimental_df)}, Control group n={len(control_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f601d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Set font to Helvetica\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Color scheme (red to green gradient)\n",
    "colors = ['#d73027', '#fc8d59', '#fee090', '#d9d9d9', '#91cf60', '#66bd63', '#1a9850']\n",
    "\n",
    "# Legend labels\n",
    "legend_labels = ['1 (Not at all)', '2', '3', '4 (Neutral)', '5', '6', '7 (Extremely)']\n",
    "\n",
    "# Create legend handles\n",
    "legend_handles = [Rectangle((0, 0), 1, 1, fc=color) for color in colors]\n",
    "\n",
    "# Create a figure with minimal size\n",
    "fig, ax = plt.subplots(figsize=(14, 0.8))\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the legend\n",
    "legend = ax.legend(legend_handles, legend_labels, loc='center', ncol=7, \n",
    "                   frameon=False, fontsize=12, handlelength=2, handleheight=1.5)\n",
    "\n",
    "# Adjust layout to minimize whitespace\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "# Save the legend\n",
    "plt.savefig('figures/rating_scale_legend.png', dpi=300, bbox_inches='tight', \n",
    "            pad_inches=0.1, facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Legend saved to: figures/rating_scale_legend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create the data\n",
    "data = {\n",
    "    'Measure': ['delta_neg_unintended', 'delta_trust', 'delta_unintended', 'pre_trust', \n",
    "         'pre_predict_unintended_behaviors', 'post_predict_unintended_behaviors',\n",
    "         'num_user_messages', 'post_arrived_desired_character', 'post_trust',\n",
    "         'pre_predict_negative_behaviors', 'post_predict_negative_behaviors'],\n",
    "    't': [0.611, -0.782, -1.422, -1.314, 0.855, -0.639, 1.128, -1.011, -2.065, 0.292, 0.777],\n",
    "    # 'df': [78] * 11,\n",
    "    'p': ['.543', '.437', '.159', '.193', '.395', '.525', '.263', '.315', '.042', '.771', '.440']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create alternating row colors\n",
    "row_colors = ['white' if i % 2 == 0 else '#E8E8E8' for i in range(len(df))]\n",
    "\n",
    "# Create the table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    columnwidth=[300, 100, 80, 100],  # Reduced first column width\n",
    "    header=dict(\n",
    "        values=['<b>' + col + '</b>' for col in df.columns],\n",
    "        fill_color='white',\n",
    "        align=['center', 'center', 'center', 'center'],\n",
    "        font=dict(family='Helvetica', size=18, color='black'),\n",
    "        line=dict(color='black', width=0),\n",
    "        height=30\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[df[col] for col in df.columns],\n",
    "        fill_color=[['white', '#E8E8E8'] * 6],  # Alternating colors\n",
    "        align=['left', 'center', 'center', 'center'],\n",
    "        font=dict(family='Helvetica', size=18, color='black'),\n",
    "        line=dict(color='white', width=0),\n",
    "        height=28\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=650,\n",
    "    height=400,\n",
    "    margin=dict(l=5, r=5, t=5, b=50),\n",
    "    font=dict(family='Helvetica')\n",
    ")\n",
    "\n",
    "# Add note as annotation\n",
    "fig.add_annotation(\n",
    "    text=\"<i>Note. Student's t-test.</i>\",\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=0, y=-0.1,\n",
    "    showarrow=False,\n",
    "    font=dict(size=11, family='Helvetica'),\n",
    "    xanchor='left',\n",
    "    align='left'\n",
    ")\n",
    "\n",
    "# Save the figure\n",
    "fig.write_image('figures/ttest_table.png', scale=3)\n",
    "fig.show()\n",
    "\n",
    "print(\"Table saved to: figures/ttest_table.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
